{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T20:37:43.261847Z",
     "start_time": "2018-04-18T20:37:39.755871Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "% matplotlib inline\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (LSTM, Dense, Conv2D, Input, Reshape, concatenate, MaxPooling2D,Dropout, Flatten, \n",
    "RepeatVector, UpSampling2D, Conv1D, Permute, BatchNormalization, Activation, \n",
    "                          UpSampling2D, MaxPooling1D, GlobalAveragePooling1D, Embedding)\n",
    "from keras import Model\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import backend as K\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from Vocabulary import Vocabulary\n",
    "from keras.backend import clear_session\n",
    "\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T20:37:43.267061Z",
     "start_time": "2018-04-18T20:37:43.263712Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets = ['android', 'ios', 'web']\n",
    "BACKEND = datasets[0]\n",
    "traindir = \"{}/training_features\".format(BACKEND)\n",
    "vocab_path = '../pix2code/bin/{}/'.format(BACKEND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data (tokens, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded succesfully\n"
     ]
    }
   ],
   "source": [
    "def process_string(data_dir, file):\n",
    "    \"\"\"Turns the gui descriptor files into a list of their 'words'\"\"\"\n",
    "    f = open(join(data_dir, file))\n",
    "    list_words = f.read().split()\n",
    "    new_list = []\n",
    "    for word in list_words:\n",
    "        # Remove special characters\n",
    "        special_characters = \" ,\\n\"\n",
    "        for c in special_characters:\n",
    "            word = word.replace(c, '')\n",
    "        new_list.append(word)\n",
    "    return new_list\n",
    "\n",
    "def load_data(data_dir):\n",
    "    \"\"\"Loads in the sentence and image data together.\n",
    "    Returns (sentences, images)\"\"\"\n",
    "    images = []\n",
    "    sentences = []\n",
    "    files = os.listdir(data_dir)\n",
    "    for listing in files:\n",
    "        # Load the sentence files, then the images\n",
    "        # There are less likely to be user-made files in this dir that end with .gui\n",
    "        if listing.endswith('.gui'):\n",
    "            base = listing[:-4]\n",
    "            try:\n",
    "                img_f = join(data_dir, base + '.npz')\n",
    "                img = np.load(img_f)['features']\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"Error trying to match img for {}\".format(listing))\n",
    "                continue\n",
    "            sent = process_string(data_dir, listing)\n",
    "            sentences.append(sent)\n",
    "            images.append(img)\n",
    "    return sentences, np.array(images)\n",
    "\n",
    "sentences, GUIS = load_data(traindir)\n",
    "assert len(sentences) == len(GUIS) and len(sentences) == 1500\n",
    "print(\"Loaded succesfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot\n",
    "\n",
    "Here we are drawing on files and a class from pix2code training. This Vocabulary class is from `pix2code/model/classes/Vocabulary.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = Vocabulary()\n",
    "voc.retrieve(vocab_path)\n",
    "VOCAB_SIZE = len(voc.binary_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T20:38:24.701841Z",
     "start_time": "2018-04-18T20:38:23.574258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted to one-hot succesfully\n"
     ]
    }
   ],
   "source": [
    "#Find max seq length\n",
    "max_length = 0\n",
    "for j in range(len(sentences)):\n",
    "    if len(sentences) > max_length:\n",
    "        max_length = len(sentences)\n",
    "\n",
    "def to_hot(sentences, max_length, voc):\n",
    "    hot = np.zeros((len(sentences), max_length, len(voc.binary_vocabulary)))\n",
    "    for i, sent in enumerate(sentences):\n",
    "        for j, word in enumerate(sent):\n",
    "            hot[i, j] = voc.binary_vocabulary[word]\n",
    "    return hot\n",
    "hot = to_hot(sentences, max_length, voc)\n",
    "assert len(hot) == 1500\n",
    "print(\"Converted to one-hot succesfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Model - For fine tuned embeddings\n",
    "---\n",
    "\n",
    "Embedding the DSL sentence representation into condensed, semantically-infused vector representations. *Currently unused.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T20:38:27.084892Z",
     "start_time": "2018-04-18T20:38:26.107041Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ngundotra/.conda/envs/torchenv/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#All word embeddings (size of training set x sentence length x 100(embedding dimension))\n",
    "def create_wordembeddings(sentences, EMBED_SIZE):\n",
    "    \"\"\"Creates a Word2Vec model to compress the sentence data.\n",
    "    Returns a np.array of (#sentences, sentence length, EMBED_SIZE)\"\"\"\n",
    "    from gensim.models import Word2Vec\n",
    "    \n",
    "    model = Word2Vec(sentences, min_count=1,size=EMBED_SIZE)\n",
    "    words = list(model.wv.vocab)\n",
    "    \n",
    "    wordembeddings = []\n",
    "    for sentence in sentences:\n",
    "        result_array = np.empty((0, EMBED_SIZE))\n",
    "        for word in sentence:\n",
    "            result = model[word].reshape(1, EMBED_SIZE)\n",
    "            result_array = np.append(result_array, result, axis=0)\n",
    "        result_array = np.pad(result_array, ((max_length - result_array.shape[0],0), (0,0)), 'constant', constant_values = 0)\n",
    "        wordembeddings.append(result_array)\n",
    "    wordembeddings = np.array(wordembeddings)\n",
    "    return wordembeddings\n",
    "\n",
    "wordembeddings = create_wordembeddings(sentences, VOCAB_SIZE)\n",
    "assert wordembeddings.shape[0] == 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Model Parts\n",
    "\n",
    "Currently unused. Used in previous iterations to repeat 3D embedding data. For example repeating a (16, 16, 16) embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T20:38:29.800684Z",
     "start_time": "2018-04-18T20:38:29.769226Z"
    }
   },
   "outputs": [],
   "source": [
    "#Custom Layer to get from 3D -> 4D\n",
    "class RepeatVector4D(Layer):\n",
    "    def __init__(self, n, **kwargs):\n",
    "        self.n = n\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "        super(RepeatVector4D, self).__init__(**kwargs)\n",
    "        \n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.n, input_shape[1], input_shape[2])\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.n, input_shape[1], input_shape[2])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        x = K.expand_dims(x, 1)\n",
    "        pattern = K.stack([1, self.n, 1, 1])\n",
    "        return K.tile(x, pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Design\n",
    "\n",
    "Functions that help the model design process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frozen(model_path, freeze=False):\n",
    "    model = keras.models.load_model(model_path)\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False if freeze else True\n",
    "    return model\n",
    "\n",
    "def unroll_v0(model, prev):\n",
    "    \"\"\"Ties the decoder portion of the autoencoder-v0 models from another notebook.\"\"\"\n",
    "    for layer in model.layers[5:]:\n",
    "        prev = layer(prev)\n",
    "    return prev\n",
    "\n",
    "def unroll_v1(model, prev):\n",
    "    \"\"\"Ties the decoder portion of the autoencoder-v1 models from another notebook.\"\"\"\n",
    "    count = 0\n",
    "    for layer in model.layers[-10:]:\n",
    "        prev = layer(prev)\n",
    "    return prev\n",
    "\n",
    "def make_callback(model, dataset):\n",
    "    \"\"\"Creates a lambda callback that plots the models prediction on the first 20 pictures of the dataset.\"\"\"\n",
    "    def callback(epoch, logs):\n",
    "        gif_range(model, dataset, start=0, stop=20)\n",
    "    return keras.callbacks.LambdaCallback(on_epoch_end=callback)\n",
    "\n",
    "def shuffle_weights(model, weights=None):\n",
    "    \"\"\"\n",
    "    @author: jklient\n",
    "    @source: https://github.com/keras-team/keras/issues/341\n",
    "\n",
    "    Randomly permute the weights in `model`, or the given `weights`.\n",
    "\n",
    "    This is a fast approximation of re-initializing the weights of a model.\n",
    "\n",
    "    Assumes weights are distributed independently of the dimensions of the weight tensors\n",
    "      (i.e., the weights have the same distribution along each dimension).\n",
    "\n",
    "    :param Model model: Modify the weights of the given model.\n",
    "    :param list(ndarray) weights: The model's weights will be replaced by a random permutation of these weights.\n",
    "      If `None`, permute the model's current weights.\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = model.get_weights()\n",
    "    weights = [np.random.permutation(w.flat).reshape(w.shape) for w in weights]\n",
    "    # Faster, but less random: only permutes along the first dimension\n",
    "    # weights = [np.random.permutation(w) for w in weights]\n",
    "    model.set_weights(weights)\n",
    "    \n",
    "def gif_range(model, data, start=0, stop=1, save=True):\n",
    "    \"\"\"\n",
    "    Adapted from - \n",
    "    @author: Eli Bendersky\n",
    "    @source: https://eli.thegreenplace.net/2016/drawing-animated-gifs-with-matplotlib/\n",
    "    Makes a GIF that reveals the model's predictions for the first (stop-start) images in data.\n",
    "    Saves the GIF to `dsl_predictions.gif`\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    from matplotlib.animation import FuncAnimation\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    #   fig.set_tight_layout(True)\n",
    "\n",
    "    # Query the figure's on-screen size and DPI. Note that when saving the figure to\n",
    "    # a file, we need to provide a DPI for that separately.\n",
    "    #   print('fig size: {0} DPI, size in inches {1}'.format(\n",
    "    #       fig.get_dpi(), fig.get_size_inches()))\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "        \n",
    "    def update(i):\n",
    "        label = 'wordembedding {0}'.format(i)\n",
    "        # print(label)\n",
    "        ax.imshow(model.predict(np.expand_dims(data[i], axis=0))[0])\n",
    "        ax.set_xlabel(label)\n",
    "        return ax\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    anim = FuncAnimation(fig, update, frames=np.arange(start, stop), interval=70)\n",
    "    if save:\n",
    "        anim.save('dsl_predictions.gif', dpi=80, writer='imagemagick')\n",
    "    else:\n",
    "        # plt.show() will just loop the animation forever.\n",
    "        plt.show()\n",
    "    plt.close(fig)\n",
    "    \n",
    "def make_model_old(encoder_path, lstm_decoder_path, autoencoder_path='model/autoencoders-v0/ios.h5'):\n",
    "    \"\"\"A deprecated iteration of the dsl2pix model design.\"\"\"\n",
    "    # Freeze the pretrained encoder & decoder (respectively)\n",
    "    pix2code_lstm = load_frozen(encoder_path, False)\n",
    "    autoencoder = load_frozen(autoencoder_path, False)\n",
    "\n",
    "    x_in = Input(shape = (max_length, VOCAB_SIZE), name = 'x_in')\n",
    "    x_flatten = Flatten()(x_in)\n",
    "    last = Dense(912, activation='relu')(x_flatten)\n",
    "    drop_rate = 0.1\n",
    "    last = Dropout(drop_rate)(last)\n",
    "    #y_lstm = LSTM(128, return_sequences = True, input_shape=(max_length, 100))(y_in)\n",
    "    \n",
    "    b1 = Dense(48*48, activation='relu')(x_flatten)\n",
    "    b1 = Reshape((48, 48, 1))(b1)\n",
    "    b1 = Conv2D(filters=64, kernel_size=(3,3), strides=(3,3), padding='valid', \n",
    "                activation='relu', name='b1conv_1')(b1)\n",
    "    b1 = Conv2D(16, (3,3), strides=(1,1), padding='same', activation='relu')(b1)\n",
    "    last = Reshape((48, 19))(last) # Input size of pix2code's first encoder\n",
    "    last = LSTM(19, return_sequences=True)(last)\n",
    "    last = LSTM(19, return_sequences=True)(last)\n",
    "    last = pix2code_lstm(last)\n",
    "    last = LSTM(128, return_sequences = True)(last)\n",
    "    last = LSTM(256, return_sequences = True)(last)\n",
    "    last = Dropout(drop_rate)(last)\n",
    "    last = LSTM(512, return_sequences = False)(last)\n",
    "    reshape = Reshape((8,8,8))(last)\n",
    "    last = UpSampling2D((2,2), name='upsampler-trainable')(reshape)\n",
    "    last = Conv2D(32, kernel_size=(4,4), padding='same', activation='relu')(last)\n",
    "#     last = Dropout(drop_rate)(last)\n",
    "    last = Conv2D(16, kernel_size=(3,3), padding='same', activation='relu')(last)\n",
    "    last = Reshape((16,16,16))(last)\n",
    "    \n",
    "    # Load in the v0 autoencoder\n",
    "    last = keras.layers.Add()([b1, last])\n",
    "    last = Conv2D(16, kernel_size=(2,2), padding='same',activation='relu')(last)\n",
    "    last = unroll_v1(autoencoder, last)\n",
    "    \n",
    "    model = Model(x_in, last)\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "def unroll_hydra(model, last):\n",
    "    return model.layers[-1](last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1400 samples, validate on 100 samples\n",
      "Epoch 1/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2345 - val_loss: 0.1793\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 2/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1733 - val_loss: 0.1628\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 3/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1652 - val_loss: 0.1603\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 4/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1605 - val_loss: 0.1548\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 5/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1579 - val_loss: 0.1543\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 6/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1553 - val_loss: 0.1505\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 7/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1536 - val_loss: 0.1502\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 8/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1526 - val_loss: 0.1503\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 9/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1518 - val_loss: 0.1508\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 10/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1511 - val_loss: 0.1490\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 11/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1504 - val_loss: 0.1482\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 12/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1499 - val_loss: 0.1480\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 13/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1491 - val_loss: 0.1455\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 14/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1489 - val_loss: 0.1468\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 15/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1483 - val_loss: 0.1455\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 16/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1484 - val_loss: 0.1454\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 17/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1478 - val_loss: 0.1459\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 18/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1480 - val_loss: 0.1452\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 19/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1473 - val_loss: 0.1454\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 20/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1474 - val_loss: 0.1451\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 21/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1471 - val_loss: 0.1458\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 22/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1470 - val_loss: 0.1443\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 23/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1468 - val_loss: 0.1442\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 24/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1465 - val_loss: 0.1443\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 25/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1466 - val_loss: 0.1438\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 26/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1461 - val_loss: 0.1439\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 27/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1462 - val_loss: 0.1436\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 28/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1458 - val_loss: 0.1438\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 29/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1458 - val_loss: 0.1454\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 30/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1461 - val_loss: 0.1437\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 31/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1456 - val_loss: 0.1435\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 32/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1456 - val_loss: 0.1450\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 33/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1454 - val_loss: 0.1435\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 34/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1455 - val_loss: 0.1436\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 35/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1454 - val_loss: 0.1434\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 36/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1456 - val_loss: 0.1445\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 37/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1455 - val_loss: 0.1444\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 38/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1455 - val_loss: 0.1435\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 39/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1450 - val_loss: 0.1433\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 40/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1454 - val_loss: 0.1431\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 41/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1453 - val_loss: 0.1499\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 42/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1451 - val_loss: 0.1446\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 43/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1450 - val_loss: 0.1433\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 44/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1452 - val_loss: 0.1488\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 45/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1451 - val_loss: 0.1431\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 46/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1447 - val_loss: 0.1443\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 47/65\n",
      "1400/1400 [==============================] - 7s 5ms/step - loss: 0.1449 - val_loss: 0.1431\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6fceb26a90>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_conv(autoencoder_path):\n",
    "    \"\"\"1D conv model :/\"\"\"\n",
    "    x_in = Input(shape=(max_length, VOCAB_SIZE))\n",
    "    last = Conv1D(64, 7, padding='same', activation='relu')(x_in)\n",
    "    last = MaxPooling1D()(last)\n",
    "    last = Conv1D(64, 5, padding='same', activation='relu')(last)\n",
    "    last = Conv1D(128, 4, padding='same', activation='relu')(last)\n",
    "    last = MaxPooling1D()(last)\n",
    "    last = Flatten()(last)\n",
    "    last = Dense(1024, activation='relu')(last)\n",
    "    autoencoder = load_frozen(autoencoder_path, freeze=False)\n",
    "    last = Reshape((8, 8, 16))(last)\n",
    "    last = UpSampling2D()(last)\n",
    "    last = unroll_hydra(autoencoder, last)\n",
    "    model = Model(x_in, last)\n",
    "    model.compile(RMSprop(lr=0.01), loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "\n",
    "clear_session()\n",
    "model = make_conv('ios-hydra-model')\n",
    "# Uncomment to see the number of model parameters\n",
    "# model.summary()\n",
    "val_plot = make_callback(model, hot[1400:])\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=7)\n",
    "model.fit(hot[:1400], GUIS[:1400], callbacks=[val_plot, early_stop],\n",
    "          validation_data=(hot[1400:], GUIS[1400:]),epochs=65, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dsl2pix-{}'.format(BACKEND))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gui descriptor:\t stack { row { label switch } row { label btn-add } row { img img img } row { label switch } row { label btn-add } row { label slider label } row { label slider label } row { label btn-add } } footer { btn-download btn-download btn-more }\n",
      "Counter({'{': 10, '}': 10, 'label': 9, 'row': 8, 'btn-add': 3, 'img': 3, 'switch': 2, 'slider': 2, 'btn-download': 2, 'stack': 1, 'footer': 1, 'btn-more': 1})\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7052b239b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def compare(sentences, hot, pics, idx):\n",
    "    \"\"\"Compares the results of the model.\n",
    "\n",
    "    Displays the input to the model, output of the model on the input, and ground truth.\n",
    "    Input to the model is chosen as the hot[idx].\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "    for ax in axes:\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticks([])\n",
    "    \n",
    "    axes[0].imshow(model.predict(np.expand_dims(hot[idx], 0))[0])\n",
    "    axes[0].set_xlabel(\"Predicted GUI\")\n",
    "    axes[1].imshow(pics[idx])\n",
    "    axes[1].set_xlabel(\"Actual GUI\")\n",
    "    \n",
    "    print('gui descriptor:\\t', ' '.join(sentences[idx]))\n",
    "    count = Counter(sentences[idx])\n",
    "    print(count)\n",
    "    return count\n",
    "        \n",
    "count = compare(sentences, hot, GUIS, 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM-Based Model\n",
    "\n",
    "This model is based off the pix2code model design. This model uses lstms to encode the token data, and loads in pretrained lstms from the pix2code models. Super slow to train ~3min/epoch. Not sure if converges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ngundotra/.conda/envs/torchenv/lib/python3.6/site-packages/keras/models.py:255: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "1200/1200 [==============================] - 207s 173ms/step - loss: 0.1852 - val_loss: 0.1779\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 2/200\n",
      "1200/1200 [==============================] - 207s 172ms/step - loss: 0.1746 - val_loss: 0.1805\n",
      "fig size: 72.0 DPI, size in inches [6. 4.]\n",
      "Epoch 3/200\n",
      " 576/1200 [=============>................] - ETA: 1:44 - loss: 0.1731"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-cb6390c1a4f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# shuffle_weights(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGUIS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/torchenv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.conda/envs/torchenv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torchenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torchenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torchenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torchenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torchenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torchenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def make_model(encoder_path, lstm_decoder_path, autoencoder_path):\n",
    "    # Freeze the pretrained encoder & decoder (respectively)\n",
    "    pix2code_lstm = load_frozen(encoder_path, False)\n",
    "    lstm_decoder = load_frozen(lstm_decoder_path, False)\n",
    "    autoencoder = load_frozen(autoencoder_path, False)\n",
    "\n",
    "    #Input DSL -> Intermediate Encoding through convolution\n",
    "    x_in = Input(shape = (max_length, 19), name = 'x_in')\n",
    "    drop_rate = 0.01\n",
    "#     last = Dropout(drop_rate)(last)\n",
    "#     #y_lstm = LSTM(128, return_sequences = True, input_shape=(max_length, 100))(y_in)\n",
    "    \n",
    "#     b1 = Dense(48*48, activation='relu')(x_flatten)\n",
    "#     b1 = Reshape((48, 48, 1))(b1)\n",
    "#     b1 = Conv2D(filters=64, kernel_size=(3,3), strides=(3,3), padding='valid', \n",
    "#                 activation='relu', name='b1conv_1')(b1)\n",
    "#     b1 = Conv2D(16, (3,3), strides=(1,1), padding='same', activation='relu')(b1)\n",
    "#     last = Reshape((48, 19))(last) # Input size of pix2code's first encoder\n",
    "    last = pix2code_lstm(x_in)\n",
    "    last = LSTM(512, return_sequences = True)(last)\n",
    "    last = Dropout(drop_rate)(last)\n",
    "    last = lstm_decoder.layers[-1](last)\n",
    "    reshape = Reshape((8,8,8))(last)\n",
    "    last = UpSampling2D((2,2), name='upsampler-trainable')(reshape)\n",
    "    last = Conv2D(16, kernel_size=(3,3), padding='same', activation='relu')(last)\n",
    "    last = Reshape((16,16,16))(last)\n",
    "\n",
    "    # Load in the v0 autoencoder\n",
    "#     last = keras.layers.Add()([b1, last])\n",
    "#     last = Conv2D(16, kernel_size=(2,2), padding='same',activation='relu')(last)\n",
    "    last = unroll_hydra(autoencoder, last)\n",
    "    \n",
    "    model = Model(x_in, last)\n",
    "    opt = RMSprop(lr=0.001)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "clear_session()\n",
    "model = make_model('ios-p2c-encoder-LSTM', 'ios-p2c-decoder-LSTM', 'ios-hydra-model')\n",
    "# model.summary()\n",
    "callback = make_callback(model, hot)\n",
    "# shuffle_weights(model)\n",
    "model.fit(hot, GUIS, callbacks=[callback], epochs=200, batch_size=32, validation_split=0.2, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch Kernel",
   "language": "python",
   "name": "torchkern"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
